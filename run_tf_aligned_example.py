#!/usr/bin/env python3
"""
è¿è¡Œå®Œå…¨å¯¹é½ TensorFlow ç‰ˆæœ¬çš„ç¤ºä¾‹
å±•ç¤ºæ¨¡å‹ç»“æ„ã€è®­ç»ƒå¾ªç¯ã€é‡‡æ ·ç­–ç•¥ã€èšåˆæƒé‡å’Œå™ªå£°è®¡ç®—çš„å®Œå…¨åŒ¹é…
"""

import torch
import torch.nn as nn
import numpy as np
import sys
import os
import time
import math

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.models.cnn import MNISTCNN
from src.algorithms.fedavg import FedAvg
from src.algorithms.pfa_tf import PFA_TF
from src.algorithms.dp_fedavg_tf import DPFedAvg_TF
from src.privacy.accountant import PrivacyAccountant

def create_mock_dataset(size=1000, num_classes=10):
    """åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®é›†"""
    class MockDataset:
        def __init__(self, size, num_classes):
            self.size = size
            self.data = torch.randn(size, 784)
            self.targets = torch.randint(0, num_classes, (size,))
        
        def __len__(self):
            return self.size
        
        def __getitem__(self, idx):
            return self.data[idx], self.targets[idx]
    
    return MockDataset(size, num_classes)

def set_epsilons(filename: str, N: int) -> list:
    """è®¾ç½® epsilon å€¼ï¼ŒåŒ¹é… TensorFlow ç‰ˆæœ¬"""
    if filename == 'gauss1':
        epsilons = np.random.normal(1.0, 0.5, N)
        epsilons = np.clip(epsilons, 0.1, 10.0)
    elif filename == 'uniform1':
        epsilons = np.random.uniform(0.5, 5.0, N)
    else:
        epsilons = [1.0] * N
    
    print(f"Epsilons: {epsilons}")
    return epsilons.tolist()

def compute_noise_multiplier(N: int, L: int, T: int, epsilon: float, delta: float) -> float:
    """è®¡ç®—å™ªå£°ä¹˜æ•°ï¼ŒåŒ¹é… TensorFlow ç‰ˆæœ¬çš„å…¬å¼"""
    q = L / N
    nm = 10 * q * math.sqrt(T * (-math.log10(delta))) / epsilon
    return nm

def sample_clients(candidates: list, num_clients: int, sample_ratio: float, 
                  public_clients: list = None) -> list:
    """é‡‡æ ·å®¢æˆ·ç«¯ï¼ŒåŒ¹é… TensorFlow ç‰ˆæœ¬çš„é€»è¾‘"""
    m = int(num_clients * sample_ratio)
    if len(candidates) < m:
        return []
    
    # éšæœºé‡‡æ ·
    participants = list(np.random.permutation(candidates))[:m]
    
    # å¦‚æœæœ‰å…¬å…±å®¢æˆ·ç«¯ï¼Œç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªå…¬å…±å®¢æˆ·ç«¯å‚ä¸
    if public_clients is not None:
        check = 50
        while check and len(set(participants).intersection(set(public_clients))) == 0:
            check -= 1
            participants = list(np.random.permutation(candidates))[:m]
        
        return participants if check else []
    
    return participants

def run_fedavg_example():
    """è¿è¡Œ FedAvg ç¤ºä¾‹"""
    print("=" * 60)
    print("è¿è¡Œ FedAvg ç¤ºä¾‹ - å®Œå…¨å¯¹é½ TensorFlow ç‰ˆæœ¬")
    print("=" * 60)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ¨¡å‹ - åŒ¹é… TensorFlow æ¶æ„
    model = MNISTCNN().to(device)
    print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters())}")
    
    # åˆ›å»ºç®—æ³•
    algorithm = FedAvg(model, lr=0.1, device=device)
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    client_datasets = [create_mock_dataset(1000) for _ in range(3)]
    test_dataset = create_mock_dataset(2000)
    
    print(f"å®¢æˆ·ç«¯æ•°æ®é›†å¤§å°: {[len(ds) for ds in client_datasets]}")
    print(f"æµ‹è¯•æ•°æ®é›†å¤§å°: {len(test_dataset)}")
    
    # è®­ç»ƒå¾ªç¯ - åŒ¹é… TensorFlow çš„ local_steps
    rounds = 5
    local_steps = 20
    batch_size = 4
    
    print(f"\nå¼€å§‹è®­ç»ƒ: {rounds} è½®, æ¯è½® {local_steps} æ­¥, æ‰¹æ¬¡å¤§å° {batch_size}")
    
    for round_idx in range(rounds):
        print(f"\n--- ç¬¬ {round_idx + 1}/{rounds} è½® ---")
        
        # å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒ
        client_updates = []
        for client_id, dataset in enumerate(client_datasets):
            # ä¸‹è½½å…¨å±€æ¨¡å‹
            algorithm.set_model_state(algorithm.get_model_state())
            
            # æœ¬åœ°è®­ç»ƒ - ä½¿ç”¨ local_steps è€Œä¸æ˜¯ epochs
            start_time = time.time()
            algorithm.local_update(dataset, local_steps=local_steps, batch_size=batch_size)
            train_time = time.time() - start_time
            
            # è·å–æ›´æ–°
            client_updates.append(algorithm.get_model_state())
            print(f"å®¢æˆ·ç«¯ {client_id}: è®­ç»ƒæ—¶é—´ {train_time:.2f}s")
        
        # æœåŠ¡å™¨èšåˆ
        algorithm.aggregate_updates(client_updates)
        
        # è¯„ä¼°
        accuracy, loss = algorithm.evaluate(test_dataset, batch_size=32)
        print(f"æµ‹è¯•å‡†ç¡®ç‡: {accuracy:.2f}%, æŸå¤±: {loss:.4f}")

def run_pfa_example():
    """è¿è¡Œ PFA ç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("è¿è¡Œ PFA ç¤ºä¾‹ - å®Œå…¨å¯¹é½ TensorFlow ç‰ˆæœ¬")
    print("=" * 60)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åˆ›å»ºæ¨¡å‹
    model = MNISTCNN().to(device)
    algorithm = PFA_TF(model, lr=0.1, proj_dims=5, device=device)
    
    # è®¾ç½®å…¬å…±å®¢æˆ·ç«¯ - åŒ¹é… TensorFlow ç‰ˆæœ¬
    epsilons = [1.0, 2.0, 0.5, 1.5, 0.8, 1.2, 0.9, 1.8, 0.7, 1.3]
    algorithm.set_public_clients(epsilons)
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    client_datasets = [create_mock_dataset(1000) for _ in range(5)]
    test_dataset = create_mock_dataset(2000)
    
    print(f"å…¬å…±å®¢æˆ·ç«¯: {algorithm.public_clients}")
    print(f"ç§æœ‰å®¢æˆ·ç«¯: {[i for i in range(5) if i not in algorithm.public_clients]}")
    
    # è®­ç»ƒå¾ªç¯
    rounds = 3
    local_steps = 15
    batch_size = 4
    
    print(f"\nå¼€å§‹è®­ç»ƒ: {rounds} è½®, æ¯è½® {local_steps} æ­¥, æ‰¹æ¬¡å¤§å° {batch_size}")
    
    for round_idx in range(rounds):
        print(f"\n--- ç¬¬ {round_idx + 1}/{rounds} è½® ---")
        
        # å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒå’Œèšåˆ
        for client_id, dataset in enumerate(client_datasets):
            # ä¸‹è½½å…¨å±€æ¨¡å‹
            algorithm.set_model_state(algorithm.get_model_state())
            
            # æœ¬åœ°è®­ç»ƒ
            algorithm.local_update(dataset, local_steps=local_steps, batch_size=batch_size)
            
            # è®¡ç®—æ›´æ–°å¹¶èšåˆ - åŒ¹é… TensorFlow çš„ PFA é€»è¾‘
            global_state = algorithm.get_model_state()
            client_state = algorithm.get_model_state()
            update = {}
            for key in global_state.keys():
                update[key] = global_state[key] - client_state[key]
            
            is_public = client_id in algorithm.public_clients
            update_values = [u.detach() for u in update.values()]
            algorithm.aggregate(client_id, update_values, is_public)
            
            print(f"å®¢æˆ·ç«¯ {client_id} (å…¬å…±: {is_public}): å·²èšåˆ")
        
        # æ›´æ–°å…¨å±€æ¨¡å‹
        algorithm.update(algorithm.get_model_state())
        
        # è¯„ä¼°
        accuracy, loss = algorithm.evaluate(test_dataset, batch_size=32)
        print(f"æµ‹è¯•å‡†ç¡®ç‡: {accuracy:.2f}%, æŸå¤±: {loss:.4f}")

def run_dp_fedavg_example():
    """è¿è¡Œ DP-FedAvg ç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("è¿è¡Œ DP-FedAvg ç¤ºä¾‹ - å®Œå…¨å¯¹é½ TensorFlow ç‰ˆæœ¬")
    print("=" * 60)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åˆ›å»ºæ¨¡å‹
    model = MNISTCNN().to(device)
    
    # è®¾ç½® DP å‚æ•° - åŒ¹é… TensorFlow ç‰ˆæœ¬
    epsilon = 1.0
    delta = 1e-5
    l2_norm_clip = 1.0
    sample_rate = 0.8
    
    algorithm = DPFedAvg_TF(
        model=model,
        lr=0.1,
        device=device,
        epsilon=epsilon,
        delta=delta,
        l2_norm_clip=l2_norm_clip,
        sample_rate=sample_rate
    )
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    client_datasets = [create_mock_dataset(1000) for _ in range(3)]
    test_dataset = create_mock_dataset(2000)
    
    print(f"DP å‚æ•°: Îµ={epsilon}, Î´={delta}, è£å‰ª={l2_norm_clip}")
    
    # è®­ç»ƒå¾ªç¯
    rounds = 3
    local_steps = 10
    batch_size = 4
    
    print(f"\nå¼€å§‹è®­ç»ƒ: {rounds} è½®, æ¯è½® {local_steps} æ­¥, æ‰¹æ¬¡å¤§å° {batch_size}")
    
    for round_idx in range(rounds):
        print(f"\n--- ç¬¬ {round_idx + 1}/{rounds} è½® ---")
        
        # å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒ
        client_updates = []
        for client_id, dataset in enumerate(client_datasets):
            # ä¸‹è½½å…¨å±€æ¨¡å‹
            algorithm.set_model_state(algorithm.get_model_state())
            
            # æœ¬åœ°è®­ç»ƒ - åº”ç”¨ DP
            algorithm.local_update(dataset, local_steps=local_steps, batch_size=batch_size)
            
            # è·å–æ›´æ–°
            client_updates.append(algorithm.get_model_state())
            
            # æ£€æŸ¥éšç§é¢„ç®—
            if algorithm.is_budget_exhausted():
                print(f"å®¢æˆ·ç«¯ {client_id}: éšç§é¢„ç®—è€—å°½!")
                break
        
        # æœåŠ¡å™¨èšåˆ
        algorithm.aggregate_updates(client_updates)
        
        # è¯„ä¼°
        accuracy, loss = algorithm.evaluate(test_dataset, batch_size=32)
        privacy_info = algorithm.get_privacy_info()
        
        print(f"æµ‹è¯•å‡†ç¡®ç‡: {accuracy:.2f}%, æŸå¤±: {loss:.4f}")
        print(f"éšç§æ¶ˆè€—: Îµ={privacy_info['epsilon_spent']:.4f}, "
              f"å‰©ä½™={privacy_info['remaining_epsilon']:.4f}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ PyTorch å®ç°å®Œå…¨å¯¹é½ TensorFlow ç‰ˆæœ¬")
    print("=" * 60)
    print("âœ… æ¨¡å‹ç»“æ„: å®Œå…¨åŒ¹é… TensorFlow çš„ CNN æ¶æ„")
    print("âœ… è®­ç»ƒå¾ªç¯: ä½¿ç”¨ local_steps è€Œä¸æ˜¯ epochs")
    print("âœ… é‡‡æ ·ç­–ç•¥: åŒ¹é… TensorFlow çš„å®¢æˆ·ç«¯é‡‡æ ·é€»è¾‘")
    print("âœ… èšåˆæƒé‡: å®ç° PFA çš„å…¬å…±/ç§æœ‰å®¢æˆ·ç«¯åˆ†ç±»")
    print("âœ… å™ªå£°è®¡ç®—: ä½¿ç”¨ TensorFlow ç‰ˆæœ¬çš„ç®€åŒ–å…¬å¼")
    print("=" * 60)
    
    try:
        # è¿è¡Œå„ç§ç®—æ³•ç¤ºä¾‹
        run_fedavg_example()
        run_pfa_example()
        run_dp_fedavg_example()
        
        print("\nğŸ‰ æ‰€æœ‰ç¤ºä¾‹è¿è¡ŒæˆåŠŸ!")
        print("PyTorch å®ç°å·²å®Œå…¨å¯¹é½ TensorFlow ç‰ˆæœ¬çš„æ‰€æœ‰å…³é”®ç»„ä»¶ã€‚")
        
    except Exception as e:
        print(f"\nâŒ è¿è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main()

