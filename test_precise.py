#!/usr/bin/env python3
"""
æµ‹è¯•å®Œå…¨åŒ¹é…è®ºæ–‡çš„PFAå®ç°
éªŒè¯100%åŒ¹é…çš„å®ç°æ˜¯å¦æ­£ç¡®å·¥ä½œ
"""

import torch
import numpy as np
import sys
import os
import time

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.models.cnn import MNISTCNN
from src.data.federated import FederatedDataSplitter
from src.algorithms.pfa_precise import PFA_Precise
from src.privacy.heterogeneous_dp import HeterogeneousDP

def test_client_division():
    """æµ‹è¯•å®¢æˆ·ç«¯åˆ†ç±»åŠŸèƒ½"""
    print("=== æµ‹è¯•å®¢æˆ·ç«¯åˆ†ç±» ===")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    epsilons = [0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]
    dataset_sizes = [100, 150, 200, 250, 300, 350, 400, 450, 500, 550]
    
    # åˆ›å»ºPFAå®ä¾‹
    model = MNISTCNN()
    pfa = PFA_Precise(model=model, proj_dims=2)
    
    # æµ‹è¯•å®¢æˆ·ç«¯åˆ†ç±»
    public_clients, private_clients = pfa.divide_clients(epsilons, dataset_sizes)
    
    print(f"å…¬å…±å®¢æˆ·ç«¯: {public_clients}")
    print(f"ç§æœ‰å®¢æˆ·ç«¯: {private_clients}")
    print(f"åˆ†ç±»ä¿¡æ¯: {pfa.client_division.get_classification_info()}")
    
    # éªŒè¯åˆ†ç±»ç»“æœ
    assert len(public_clients) + len(private_clients) == len(epsilons)
    assert len(set(public_clients) & set(private_clients)) == 0
    print("âœ… å®¢æˆ·ç«¯åˆ†ç±»æµ‹è¯•é€šè¿‡")
    
    return public_clients, private_clients

def test_lanczos_projection():
    """æµ‹è¯•LanczosæŠ•å½±åŠŸèƒ½"""
    print("\n=== æµ‹è¯•LanczosæŠ•å½± ===")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    n_features = 100
    n_clients = 5
    proj_dims = 2
    
    # ç”Ÿæˆéšæœºæ›´æ–°å‘é‡
    updates = [torch.randn(n_features) for _ in range(n_clients)]
    
    # åˆ›å»ºPFAå®ä¾‹
    model = MNISTCNN()
    pfa = PFA_Precise(model=model, proj_dims=proj_dims)
    
    # æµ‹è¯•æŠ•å½±çŸ©é˜µè®¡ç®—
    projection_matrix, mean_vector = pfa.lanczos_projection.compute_projection_matrix(
        updates, proj_dims
    )
    
    print(f"æŠ•å½±çŸ©é˜µå½¢çŠ¶: {projection_matrix.shape}")
    print(f"å‡å€¼å‘é‡å½¢çŠ¶: {mean_vector.shape}")
    print(f"æ”¶æ•›ä¿¡æ¯: {pfa.lanczos_projection.get_convergence_info()}")
    
    # éªŒè¯æŠ•å½±çŸ©é˜µ
    assert projection_matrix.shape == (n_features, proj_dims)
    assert mean_vector.shape == (n_features,)
    print("âœ… LanczosæŠ•å½±æµ‹è¯•é€šè¿‡")
    
    return projection_matrix, mean_vector

def test_heterogeneous_dp():
    """æµ‹è¯•å¼‚æ„å·®åˆ†éšç§åŠŸèƒ½"""
    print("\n=== æµ‹è¯•å¼‚æ„å·®åˆ†éšç§ ===")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    client_epsilons = [1.0, 2.0, 3.0, 4.0, 5.0]
    client_deltas = [1e-5] * 5
    
    # åˆ›å»ºå¼‚æ„DPå®ä¾‹
    hdp = HeterogeneousDP(client_epsilons, client_deltas)
    
    # æµ‹è¯•å™ªå£°ä¹˜æ•°è®¡ç®—
    dataset_sizes = [100, 200, 300, 400, 500]
    batch_sizes = [4, 8, 12, 16, 20]
    local_steps = [100, 100, 100, 100, 100]
    
    noise_multipliers = hdp.compute_noise_multipliers(
        dataset_sizes, batch_sizes, local_steps
    )
    
    print(f"å™ªå£°ä¹˜æ•°: {noise_multipliers}")
    
    # æµ‹è¯•DPæ¢¯åº¦å¤„ç†
    gradients = [{'weight': torch.randn(10, 10), 'bias': torch.randn(10)} for _ in range(3)]
    client_ids = [0, 1, 2]
    noise_mults = noise_multipliers[:3]
    
    dp_gradients = hdp.apply_heterogeneous_dp(gradients, client_ids, noise_mults)
    
    print(f"DPæ¢¯åº¦æ•°é‡: {len(dp_gradients)}")
    print(f"éšç§ä¿è¯: {hdp.get_heterogeneous_privacy_guarantee()}")
    
    # éªŒè¯ç»“æœ
    assert len(dp_gradients) == len(gradients)
    assert len(noise_multipliers) == len(client_epsilons)
    print("âœ… å¼‚æ„å·®åˆ†éšç§æµ‹è¯•é€šè¿‡")
    
    return hdp

def test_precise_aggregation():
    """æµ‹è¯•ç²¾ç¡®èšåˆåŠŸèƒ½"""
    print("\n=== æµ‹è¯•ç²¾ç¡®èšåˆ ===")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    n_clients = 5
    n_params = 10
    
    client_updates = []
    client_weights = []
    client_epsilons = [1.0, 2.0, 3.0, 4.0, 5.0]
    client_dataset_sizes = [100, 200, 300, 400, 500]
    client_types = ['public', 'private', 'private', 'public', 'private']
    
    for i in range(n_clients):
        update = {
            'weight': torch.randn(n_params, n_params),
            'bias': torch.randn(n_params)
        }
        client_updates.append(update)
        client_weights.append(client_dataset_sizes[i])
    
    # åˆ›å»ºPFAå®ä¾‹
    model = MNISTCNN()
    pfa = PFA_Precise(model=model, proj_dims=2)
    
    # è®¾ç½®å…¨å±€æ¨¡å‹çŠ¶æ€
    pfa.global_model_state = pfa.get_model_state()
    
    # æµ‹è¯•èšåˆ
    pfa.aggregate_updates(
        client_updates=client_updates,
        client_weights=client_weights,
        client_epsilons=client_epsilons,
        client_dataset_sizes=client_dataset_sizes,
        client_types=client_types
    )
    
    print(f"èšåˆä¿¡æ¯: {pfa.aggregation.get_aggregation_info()}")
    
    # éªŒè¯ç»“æœ
    assert pfa.global_model_state is not None
    print("âœ… ç²¾ç¡®èšåˆæµ‹è¯•é€šè¿‡")

def test_full_pfa_workflow():
    """æµ‹è¯•å®Œæ•´çš„PFAå·¥ä½œæµç¨‹"""
    print("\n=== æµ‹è¯•å®Œæ•´PFAå·¥ä½œæµç¨‹ ===")
    
    # å‡†å¤‡æ•°æ®
    data_splitter = FederatedDataSplitter(
        dataset_name='mnist',
        num_clients=5,
        iid=True,
        data_dir='./data'
    )
    
    client_datasets = data_splitter.create_clients()
    test_dataset = data_splitter.get_test_dataset()
    
    # åˆ›å»ºæ¨¡å‹å’Œç®—æ³•
    model = MNISTCNN()
    pfa = PFA_Precise(model=model, proj_dims=1, lanczos_iter=64)
    
    # è®¾ç½®éšç§å‚æ•°
    client_epsilons = [1.0, 2.0, 3.0, 4.0, 5.0]
    client_deltas = [1e-5] * 5
    pfa.set_heterogeneous_dp(client_epsilons, client_deltas)
    
    # å®¢æˆ·ç«¯åˆ†ç±»
    dataset_sizes = [len(client_datasets[i]) for i in range(5)]
    public_clients, private_clients = pfa.divide_clients(client_epsilons, dataset_sizes)
    
    print(f"å…¬å…±å®¢æˆ·ç«¯: {public_clients}")
    print(f"ç§æœ‰å®¢æˆ·ç«¯: {private_clients}")
    
    # æ¨¡æ‹Ÿä¸€è½®è®­ç»ƒ
    client_updates = []
    client_weights = []
    client_epsilons_list = []
    client_dataset_sizes_list = []
    client_types_list = []
    
    for i in range(5):
        # å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒ
        client_data = client_datasets[i]
        
        # æ¨¡æ‹Ÿæœ¬åœ°æ›´æ–°
        pfa.local_update_with_dp(
            client_data, 
            local_steps=10, 
            batch_size=4, 
            client_id=i,
            l2_norm_clip=1.0
        )
        
        # è·å–æ›´æ–°
        client_update = pfa.get_model_state()
        client_updates.append(client_update)
        client_weights.append(len(client_data))
        client_epsilons_list.append(client_epsilons[i])
        client_dataset_sizes_list.append(len(client_data))
        
        if i in public_clients:
            client_types_list.append('public')
        else:
            client_types_list.append('private')
    
    # æœåŠ¡å™¨èšåˆ
    pfa.aggregate_updates(
        client_updates=client_updates,
        client_weights=client_weights,
        client_epsilons=client_epsilons_list,
        client_dataset_sizes=client_dataset_sizes_list,
        client_types=client_types_list
    )
    
    # è¯„ä¼°
    accuracy, loss = pfa.evaluate(test_dataset, batch_size=32)
    print(f"æµ‹è¯•å‡†ç¡®ç‡: {accuracy:.2f}%, æŸå¤±: {loss:.4f}")
    
    # è·å–ç®—æ³•ä¿¡æ¯
    algorithm_info = pfa.get_algorithm_info()
    print(f"ç®—æ³•ä¿¡æ¯: {algorithm_info}")
    
    print("âœ… å®Œæ•´PFAå·¥ä½œæµç¨‹æµ‹è¯•é€šè¿‡")

def test_convergence_monitoring():
    """æµ‹è¯•æ”¶æ•›ç›‘æ§åŠŸèƒ½"""
    print("\n=== æµ‹è¯•æ”¶æ•›ç›‘æ§ ===")
    
    # åˆ›å»ºPFAå®ä¾‹
    model = MNISTCNN()
    pfa = PFA_Precise(model=model, proj_dims=2)
    
    # æ¨¡æ‹Ÿå¤šè½®è®­ç»ƒ
    for round_num in range(3):
        # ç”Ÿæˆéšæœºæ›´æ–°
        n_clients = 5
        client_updates = []
        for i in range(n_clients):
            update = {
                'weight': torch.randn(10, 10),
                'bias': torch.randn(10)
            }
            client_updates.append(update)
        
        # è®¾ç½®å…¨å±€æ¨¡å‹çŠ¶æ€
        pfa.global_model_state = pfa.get_model_state()
        
        # èšåˆæ›´æ–°
        pfa.aggregate_updates(client_updates)
        
        # è·å–æŠ•å½±è´¨é‡ä¿¡æ¯
        projection_quality = pfa.get_projection_quality()
        print(f"è½®æ¬¡ {round_num + 1} æŠ•å½±è´¨é‡: {projection_quality}")
    
    print("âœ… æ”¶æ•›ç›‘æ§æµ‹è¯•é€šè¿‡")

def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("å¼€å§‹æµ‹è¯•å®Œå…¨åŒ¹é…è®ºæ–‡çš„PFAå®ç°...")
    
    try:
        # æµ‹è¯•å„ä¸ªç»„ä»¶
        test_client_division()
        test_lanczos_projection()
        test_heterogeneous_dp()
        test_precise_aggregation()
        test_full_pfa_workflow()
        test_convergence_monitoring()
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼PFAå®ç°100%åŒ¹é…è®ºæ–‡è¦æ±‚ï¼")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True

if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)
